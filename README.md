# ðŸ§  Simple GPT API: llm-support-api
A REST API built with FastAPI that allows you to submit questions, processes them with a language model (such as GPT-4), and saves the history in a database. Ideal for scenarios such as automated support, chatbots, or text classification.

## ðŸ“¦ Technologies Used

- Python 3.11
- FastAPI
- OpenAI Python SDK (>=1.0.0)
- Uvicorn
- python-dotenv
- Async support

## ðŸš€ How It Works

This project offers a single POST endpoint `/ask` where you can send a message, and it returns a response generated by the GPT model.

### Example Request

```http
POST /ask
Content-Type: application/json

{
  "message": "What is the capital of France?"
}
``````

### Example Response
```http
{
  "response": "The capital of France is Paris."
}
``````

## Setup
1. Clone the repository:
```
git clone https://github.com/your-username/simple-gpt-api.git
cd simple-gpt-api
```
2. Create a virtual environment and install dependencies:
```
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```
3. Create a .env file with your OpenAI API key:
```
OPENAI_API_KEY=your-api-key-here
```
4. Run the server:
```
uvicorn app.main:app --reload
```
5. Visit the interactive API docs:
```
http://localhost:8000/docs
```

## Project Structure
```
.
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ main.py         # FastAPI app and route definition
â”‚   â”œâ”€â”€ schemas.py      # Request and response schemas
â”‚   â””â”€â”€ services.py     # GPT interaction logic
â”œâ”€â”€ .env                # API key (not tracked by git)
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
```